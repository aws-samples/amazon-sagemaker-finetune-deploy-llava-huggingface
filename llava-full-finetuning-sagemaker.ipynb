{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLaVA Training Scripts for SageMaker\n",
    "\n",
    "Create a SageMaker training script which is adapted from LLaVA/scripts/v1_5/finetune_task.sh.\n",
    "According to LLaVA, per_device_train_batch_size * gradient_accumulation_steps * number of devices = 128\n",
    "This setting is tested on ml.p4d.24xlarge (8 * A100[40G])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile LLaVA/finetune-full-piechart-QA.sh\n",
    "\n",
    "#!/bin/bash\n",
    "export WANDB_MODE=offline\n",
    "\n",
    "cd /opt/ml/code\n",
    "pip install -e . --no-deps\n",
    "\n",
    "deepspeed llava/train/train_mem.py \\\n",
    "    --deepspeed ./scripts/zero3.json \\\n",
    "    --model_name_or_path liuhaotian/llava-v1.5-7b \\\n",
    "    --version v1 \\\n",
    "    --data_path /opt/ml/input/data/piechart/piechart-QA.jsonl \\\n",
    "    --image_folder /opt/ml/input/data//piechart/piechart-QA \\\n",
    "    --vision_tower openai/clip-vit-large-patch14-336 \\\n",
    "    --mm_projector_type mlp2x_gelu \\\n",
    "    --mm_vision_select_layer -2 \\\n",
    "    --mm_use_im_start_end False \\\n",
    "    --mm_use_im_patch_token False \\\n",
    "    --image_aspect_ratio pad \\\n",
    "    --group_by_modality_length True \\\n",
    "    --bf16 True \\\n",
    "    --output_dir /opt/ml/checkpoints/$(job_id) \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 4 \\\n",
    "    --gradient_accumulation_steps 2 \\\n",
    "    --evaluation_strategy \"no\" \\\n",
    "    --save_strategy \"steps\" \\\n",
    "    --save_steps 50000 \\\n",
    "    --save_total_limit 1 \\\n",
    "    --learning_rate 2e-5 \\\n",
    "    --weight_decay 0. \\\n",
    "    --warmup_ratio 0.03 \\\n",
    "    --lr_scheduler_type \"cosine\" \\\n",
    "    --logging_steps 1 \\\n",
    "    --tf32 True \\\n",
    "    --model_max_length 2048 \\\n",
    "    --gradient_checkpointing True \\\n",
    "    --dataloader_num_workers 4 \\\n",
    "    --lazy_preprocess True \\\n",
    "    --report_to wandb\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sagemaker session and get the training data s3 uri\n",
    "import json\n",
    "import time\n",
    "import boto3\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import sagemaker.huggingface\n",
    "import os\n",
    "\n",
    "ROLE = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "BUCKET = \"YOUR_S3_BUCKET\"\n",
    "PREFIX = \"data\"\n",
    "s3uri = os.path.join(\"s3://\", BUCKET, PREFIX)\n",
    "print(f\"sagemaker role arn: {ROLE}\")\n",
    "print(f\"sagemaker bucket: {BUCKET}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "print(f\"data uri: {s3uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique training job id\n",
    "from time import gmtime, strftime\n",
    "job_id = \"llava-v15-7b-task-full-\"+strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(job_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = {\n",
    "        'job_id': job_id\n",
    "}\n",
    "\n",
    "# Define metrics definitions, such metrics will be extracted from training script's printed logs and send to cloudwatch\n",
    "metric_definitions=[\n",
    "        {'Name': 'loss', 'Regex': \"'loss': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'learning_rate', 'Regex': \"'learning_rate': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'epoch', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'train_runtime', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'train_samples_per_second', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'train_steps_per_second', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"},\n",
    "        {'Name': 'train_loss', 'Regex': \"'epoch': ([0-9]+(.|e\\-)[0-9]+),?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point the training data to the s3 uri. Use FastFile to \"mount\" the s3 files directly instead of copying to local disk\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "training_input = TrainingInput(\n",
    "    s3_data_type='S3Prefix', # Available Options: S3Prefix | ManifestFile | AugmentedManifestFile\n",
    "    s3_data=s3uri,\n",
    "    distribution='FullyReplicated', # Available Options: FullyReplicated | ShardedByS3Key \n",
    "    input_mode='FastFile'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "instance_type = 'ml.p4d.24xlarge'\n",
    "use_spot_instances = False\n",
    "max_run=6000\n",
    "max_wait = 1200 if use_spot_instances else None\n",
    "keep_alive_period_in_seconds = None\n",
    "\n",
    "output_uri = os.path.join(\"s3://\", BUCKET, job_id, \"output\")\n",
    "checkpoint_uri = os.path.join(\"s3://\", BUCKET, job_id, \"checkpoints\")\n",
    "\n",
    "huggingface_estimator = HuggingFace(entry_point='finetune-full-piechart-QA.sh',\n",
    "                                    source_dir='./LLaVA',\n",
    "                                    instance_type=instance_type,\n",
    "                                    instance_count=1,\n",
    "                                    py_version='py310',\n",
    "                                    image_uri='YOUR_TRAINING_IMAGE_URI',\n",
    "                                    role=ROLE,\n",
    "                                    metric_definitions = metric_definitions,\n",
    "                                    environment=environment,\n",
    "                                    use_spot_instances=use_spot_instances,\n",
    "                                    max_run=max_run,\n",
    "                                    max_wait=max_wait,\n",
    "                                    output_path=output_uri,\n",
    "                                    checkpoint_s3_uri=checkpoint_uri,\n",
    "                                    keep_alive_period_in_seconds=keep_alive_period_in_seconds,\n",
    "                                   )\n",
    "\n",
    "huggingface_estimator.fit({'piechart': training_input}, job_name=job_id)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
